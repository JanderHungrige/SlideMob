{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "#pptx transformation imports\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "#spellcheck imports\n",
    "from spellchecker import SpellChecker\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "# translator import\n",
    "import xml.etree.ElementTree as ET\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerpointPipeline:\n",
    "    def __init__(self, \n",
    "                 model: str=\"gpt-4\", \n",
    "                 pydentic_model: str=\"gpt-4-turbo-preview\", \n",
    "                 client:str=\"OpenAI\", \n",
    "                 verbose: bool=False,\n",
    "                 extract_namespaces: bool=False,\n",
    "                 namespaces: dict={'a': 'http://schemas.openxmlformats.org/drawingml/2006/main',\n",
    "                                   'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships',\n",
    "                                   'p': 'http://schemas.openxmlformats.org/presentationml/2006/main',\n",
    "                                   'p14':\"http://schemas.microsoft.com/office/powerpoint/2010/main\",\n",
    "                                   'a16':\"http://schemas.microsoft.com/office/drawing/2014/main\",\n",
    "                                   'mc':\"http://schemas.openxmlformats.org/markup-compatibility/2006\",\n",
    "                                   'v':\"urn:schemas-microsoft-com:vml\"\n",
    "                                   },\n",
    "                 ):\n",
    "        #load config file\n",
    "        with open(\"config.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        self.root_folder = config[\"root_folder\"]\n",
    "        self.pptx_folder = config[\"pptx_folder\"]\n",
    "        self.pptx_name = config[\"pptx_name\"]\n",
    "        self.extract_folder = config[\"extract_folder\"]\n",
    "        self.output_folder = config[\"output_folder\"]\n",
    "\n",
    "\n",
    "        self.openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.model = model\n",
    "        self.pydentic_model=pydentic_model\n",
    "        self.client = client\n",
    "        self.extract_namespaces = extract_namespaces\n",
    "        self.namespaces =namespaces \n",
    "\n",
    "        self.pptx_path = os.path.join(self.root_folder, self.pptx_folder, self.pptx_name)\n",
    "        if verbose: print(f\"\\tPPTX path: {self.pptx_path}\")\n",
    "        self.extract_path = os.path.join(self.root_folder, self.extract_folder)\n",
    "        if verbose: print(f\"\\tExtract path: {self.extract_path}\")\n",
    "        self.output_folder = os.path.join(self.root_folder, self.output_folder)\n",
    "        if verbose: print(f\"\\tOutput folder: {self.output_folder}\")\n",
    "        self.output_pptx_name = f'translated_{self.pptx_name}'\n",
    "        if verbose: print(f\"\\tOutput PPTX name: {self.output_pptx_name}\")\n",
    "        \n",
    "        if client == \"OpenAI\":\n",
    "            self.client = OpenAI(api_key=self.openai_api_key)\n",
    "        else:\n",
    "            print(\"\\tClient not supported (So far only OpenAI is supported)\")\n",
    "      \n",
    "    def find_slide_files(self, root_folder: str) -> List[str]:\n",
    "            \"\"\"Find all slide XML files in the folder structure.\"\"\"\n",
    "            slide_files = []\n",
    "            for root, _, files in os.walk(root_folder):\n",
    "                for file in files:\n",
    "                    if file.startswith('slide') and file.endswith('.xml'):\n",
    "                        number_part = file[5:-4]\n",
    "                        if number_part.isdigit():\n",
    "                            slide_files.append(os.path.join(root, file))\n",
    "            return sorted(slide_files)\n",
    "    \n",
    "    def extract_paragraphs(self, xml_file: str) -> List[ET.Element]:\n",
    "        \"\"\"Extract everything inparagraphs from the XML file.\"\"\"\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        return root.findall('.//a:p', self.namespaces)\n",
    "\n",
    "    def extract_text_runs(self, xml_file: str) -> Tuple[List[ET.Element], set]:\n",
    "        \"\"\"Extract text elements that need translation.\"\"\"\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        text_elements = []\n",
    "        original_text_elements = set()\n",
    "  \n",
    "        # Create a backup with the original text elements\n",
    "        for paragraph in root.findall('.//a:p', self.namespaces):\n",
    "            for run in paragraph.findall('.//a:r', self.namespaces):\n",
    "                run_props = run.find('.//a:rPr', self.namespaces)\n",
    "                lang = run_props.get('lang') if run_props is not None else 'en-GB' \n",
    "\n",
    "                for original_text_element in run.findall('.//a:t', self.namespaces):\n",
    "                    if original_text_element.text and original_text_element.text.strip():\n",
    "                        original_text_elements.add(original_text_element.text.strip())\n",
    "\n",
    "        # Process paragraphs while preserving structure\n",
    "        for paragraph in root.findall('.//a:p', self.namespaces):\n",
    "            text_parts = []\n",
    "            lang = None\n",
    "            for text_element in paragraph.findall('.//a:t', self.namespaces):\n",
    "                run_props = text_element.find('.//a:rPr', self.namespaces)\n",
    "                if run_props is not None:\n",
    "                    lang = run_props.get('lang', 'en-GB')\n",
    "                if text_element.text and text_element.text.strip():\n",
    "                    text_parts.append(text_element.text.strip())\n",
    "            \n",
    "            if text_parts:\n",
    "                text_element = ET.Element('a:t')\n",
    "                text_element.text = ' '.join(text_parts)\n",
    "                text_element.set('lang', lang or 'en-GB')\n",
    "                text_elements.append(text_element)\n",
    "\n",
    "        print(\"Text elements found:\")\n",
    "        for element in text_elements:\n",
    "            print(f\"- {element.text.strip()} | lang: {element.get('lang')}\")     \n",
    "        return text_elements, original_text_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom pptx to xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPTXTransformer(PowerpointPipeline):\n",
    "    def __init__(self, extract_path: str):\n",
    "        self.extract_path = extract_path\n",
    "        super().__init__()\n",
    "\n",
    "    def extract_pptx(self, pptx_path: str) -> str:\n",
    "        \"\"\"Extract a PPTX file into its XML components.\"\"\"\n",
    "        os.makedirs(self.extract_path, exist_ok=True)\n",
    "        \n",
    "        with zipfile.ZipFile(pptx_path, 'r') as pptx:\n",
    "            pptx.extractall(self.extract_path)\n",
    "        \n",
    "        # Get namespaces right after extraction\n",
    "        if self.extract_namespaces:\n",
    "            self.namespaces = self.get_namespace()\n",
    "        return self.extract_path\n",
    "\n",
    "    def get_namespace(self) -> dict:\n",
    "        \"\"\"Get the namespaces from the first slide XML using text processing.\"\"\"\n",
    "        slide_path = os.path.join(self.extract_path, 'ppt/slides/slide1.xml')\n",
    "        \n",
    "        try:\n",
    "            with open(slide_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                \n",
    "            # Find the root element opening tag\n",
    "            start_idx = content.find('<p:sld')\n",
    "            end_idx = content.find('>', start_idx)\n",
    "            if start_idx == -1 or end_idx == -1:\n",
    "                print(\"Could not find root element\")\n",
    "                return {}\n",
    "            \n",
    "            # Extract the root element declaration\n",
    "            root_declaration = content[start_idx:end_idx]\n",
    "            \n",
    "            # Find all xmlns declarations\n",
    "            namespaces = {}\n",
    "            import re\n",
    "            \n",
    "            # Pattern to match xmlns:prefix=\"uri\" or xmlns=\"uri\"\n",
    "            pattern = r'xmlns(?::([^=]+))?=\"([^\"]+)\"'\n",
    "            matches = re.finditer(pattern, root_declaration)\n",
    "            \n",
    "            for match in matches:\n",
    "                prefix = match.group(1)  # This might be None for default namespace\n",
    "                uri = match.group(2)\n",
    "                if prefix:\n",
    "                    namespaces[prefix] = uri\n",
    "                else:\n",
    "                    namespaces['default'] = uri\n",
    "            \n",
    "            print(\"\\tExtracted namespaces:\", namespaces)\n",
    "            return namespaces\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\tError extracting namespaces: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def compose_pptx(self, source_path: str, output_pptx: str):\n",
    "        \"\"\"Compose a PPTX file from a directory containing the XML structure.\"\"\"\n",
    "        os.makedirs(os.path.dirname(output_pptx), exist_ok=True)\n",
    "        \n",
    "        with zipfile.ZipFile(output_pptx, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "            for root, _, files in os.walk(source_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, source_path)\n",
    "                    zf.write(file_path, arcname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate xml - Spellcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideSpellChecker(PowerpointPipeline):\n",
    "    def __init__(self,Further_SpellCheckInstructions):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.spell = SpellChecker()\n",
    "        # Define namespaces used in PPTX XML\n",
    "        self.namespaces = {\n",
    "            'a': 'http://schemas.openxmlformats.org/drawingml/2006/main',\n",
    "            'p': 'http://schemas.openxmlformats.org/presentationml/2006/main'\n",
    "        }\n",
    "        ET.register_namespace('a', self.namespaces['a'])\n",
    "        ET.register_namespace('p', self.namespaces['p'])\n",
    "\n",
    "    def check_and_fix_slide(self, xml_content):\n",
    "        tree = ET.ElementTree(ET.fromstring(xml_content))\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Find all paragraphs\n",
    "        for paragraph in root.findall('.//a:p', self.namespaces):\n",
    "            self._process_paragraph(paragraph)\n",
    "            \n",
    "        return ET.tostring(root, encoding='unicode')\n",
    "\n",
    "    def _process_paragraph(self, paragraph):\n",
    "        runs = paragraph.findall('a:r', self.namespaces)\n",
    "        i = 0\n",
    "        while i < len(runs):\n",
    "            current_run = runs[i]\n",
    "            \n",
    "            # Check if current run has error attribute\n",
    "            if current_run.get('err') == '1':\n",
    "                # Store original properties\n",
    "                run_props = current_run.find('a:rPr', self.namespaces)\n",
    "                \n",
    "                # Collect text from this and adjacent runs\n",
    "                combined_text = self._collect_adjacent_text(runs, i)\n",
    "                \n",
    "                # Fix spelling and update runs\n",
    "                corrected_text = self._fix_spelling(combined_text)\n",
    "                if corrected_text != combined_text:\n",
    "                    self._update_runs_with_correction(runs, i, corrected_text, run_props)\n",
    "                    \n",
    "                # Merge runs with identical properties\n",
    "                self._merge_identical_runs(paragraph)\n",
    "            \n",
    "            # Check language consistency\n",
    "            self._check_language_consistency(current_run)\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "    def _collect_adjacent_text(self, runs, start_index):\n",
    "        \"\"\"Collects text from adjacent runs that might be part of the same word\"\"\"\n",
    "        text_parts = []\n",
    "        i = start_index\n",
    "        \n",
    "        while i < len(runs):\n",
    "            text_elem = runs[i].find('a:t', self.namespaces)\n",
    "            if text_elem is not None:\n",
    "                text_parts.append(text_elem.text)\n",
    "            i += 1\n",
    "            \n",
    "            # Stop if we hit punctuation or clear word boundary\n",
    "            if text_elem is not None and re.search(r'[.!?,\\s]$', text_elem.text):\n",
    "                break\n",
    "                \n",
    "        return ''.join(text_parts)\n",
    "\n",
    "    def _fix_spelling(self, text):\n",
    "        words = text.split()\n",
    "        corrected_words = []\n",
    "        \n",
    "        for word in words:\n",
    "            if not self.spell.correction(word) == word:\n",
    "                corrected_words.append(self.spell.correction(word))\n",
    "            else:\n",
    "                corrected_words.append(word)\n",
    "                \n",
    "        return ' '.join(corrected_words)\n",
    "\n",
    "    def _update_runs_with_correction(self, runs, start_index, corrected_text, original_props):\n",
    "        \"\"\"Updates the runs with corrected text while maintaining formatting\"\"\"\n",
    "        # Create new run with corrected text\n",
    "        new_run = ET.Element('a:r')\n",
    "        new_run.append(original_props)\n",
    "        \n",
    "        text_elem = ET.SubElement(new_run, 'a:t')\n",
    "        text_elem.text = corrected_text\n",
    "        \n",
    "        # Replace old runs with new corrected run\n",
    "        parent = runs[start_index].getparent()\n",
    "        parent.remove(runs[start_index])\n",
    "        parent.insert(start_index, new_run)\n",
    "\n",
    "    def _merge_identical_runs(self, paragraph):\n",
    "        \"\"\"Merges adjacent runs with identical properties\"\"\"\n",
    "        runs = paragraph.findall('a:r', self.namespaces)\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(runs) - 1:\n",
    "            current_run = runs[i]\n",
    "            next_run = runs[i + 1]\n",
    "            \n",
    "            if self._runs_have_identical_props(current_run, next_run):\n",
    "                # Merge text content\n",
    "                current_text = current_run.find('a:t', self.namespaces).text\n",
    "                next_text = next_run.find('a:t', self.namespaces).text\n",
    "                current_run.find('a:t', self.namespaces).text = current_text + next_text\n",
    "                \n",
    "                # Remove the merged run\n",
    "                paragraph.remove(next_run)\n",
    "                runs = paragraph.findall('a:r', self.namespaces)\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    def _runs_have_identical_props(self, run1, run2):\n",
    "        \"\"\"Checks if two runs have identical properties\"\"\"\n",
    "        props1 = run1.find('a:rPr', self.namespaces)\n",
    "        props2 = run2.find('a:rPr', self.namespaces)\n",
    "        \n",
    "        if props1 is None or props2 is None:\n",
    "            return False\n",
    "            \n",
    "        # Compare relevant attributes\n",
    "        attrs_to_compare = ['lang', 'sz', 'b', 'i', 'u']\n",
    "        return all(props1.get(attr) == props2.get(attr) for attr in attrs_to_compare)\n",
    "\n",
    "    def _check_language_consistency(self, run):\n",
    "        \"\"\"Checks and fixes language consistency within a run\"\"\"\n",
    "        run_props = run.find('a:rPr', self.namespaces)\n",
    "        if run_props is not None and run_props.get('lang') is None:\n",
    "            # Set default language if missing\n",
    "            run_props.set('lang', 'en-US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate xml - Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationResponse(BaseModel):\n",
    "    translation: str\n",
    "\n",
    "class SlideTranslator(PowerpointPipeline):\n",
    "    def __init__(self, \n",
    "                 target_language: str,\n",
    "                 Further_StyleInstructions: str = \"None\"): \n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.target_language = target_language\n",
    "        # Load language codes mapping\n",
    "        with open(\"config_languages.json\", \"r\") as f:\n",
    "            self.language_codes = json.load(f)\n",
    "\n",
    "        if Further_StyleInstructions != \"None\":\n",
    "            self.Further_StyleInstructions = f\" Here are some further wording style instructions: {self.Further_StyleInstructions}\"\n",
    "        else:\n",
    "            self.Further_StyleInstructions = \"\"\n",
    "\n",
    "    def translate_text(self, text: str) -> str:\n",
    "        \"\"\"Translate text while preserving approximate length and formatting.\"\"\"\n",
    "        prompt = f\"\"\"Translate following this instructions: \n",
    "        Maintain similar total character length and preserve any special formatting or technical terms. \n",
    "        IMPORTANT:For the translation you must not return any other text than the pure translation.\n",
    "        Keep technical terms in the translation. \n",
    "        Keep role names in the translation (e.g., DataScientist, CEO, etc.).\n",
    "        Keep names of companies in the translation (e.g., Apple, Microsoft, etc.).\n",
    "        Keep names of products in the translation (e.g., iPhone, Windows, LegalAI, etc.).\n",
    "        Make the translation sharp, concise and business-like.\n",
    "        Translate the text to {self.target_language}.\n",
    "        {self.Further_StyleInstructions}\n",
    "        IMPORTANT:For the translation you must not return any other text than the pure translation.\n",
    "        Text to translate: {text}\n",
    "        \"\"\"\n",
    "\n",
    "        pydentic_prompt_addition = f\"Respond with a JSON object containing only a 'translation' field with the {self.target_language} translation of this text\"\n",
    "        \n",
    "        if self.model == \"gpt-4\": #non pydentic model\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.3,\n",
    "                )\n",
    "                return response.choices[0].message.content.strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Translation error: {e}\")\n",
    "                return text\n",
    "        else: #pydentic model   \n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt + pydentic_prompt_addition}\n",
    "                    ],\n",
    "                    tools=[],\n",
    "                    temperature=0.3,\n",
    "                    response_format={ \"type\": \"json_object\" }\n",
    "                )\n",
    "                translation_response = TranslationResponse.model_validate_json(\n",
    "                    response.choices[0].message.content\n",
    "                )\n",
    "                return translation_response.translation.strip()\n",
    "    \n",
    "            except Exception as e:\n",
    "                if \"Error code: 400\" in str(e):\n",
    "                    print(f\"ERROR We use Pydentic, therefore the model must support json output (e.g. gpt-4-turbo-preview)| Translation error: {e}\")\n",
    "                else:\n",
    "                    print(f\"Translation error: {e}\")    \n",
    "                return text\n",
    "\n",
    "    def create_translation_map(self, text_elements: List[ET.Element], original_text_elements: set) -> dict:\n",
    "        \"\"\"Create a mapping between original text and their translations.\"\"\"\n",
    "        translation_map = {text: \"\" for text in original_text_elements}\n",
    "        \n",
    "        for element in text_elements:\n",
    "            original_text = element.text.strip()\n",
    "            source_lang = element.get('lang', 'en-GB')\n",
    "            print(f\"\\tLLM fed text: {original_text}\")\n",
    "            if original_text:\n",
    "                translated_text = self.translate_text(original_text)\n",
    "                print(f\"\\tOriginal paragraph: {original_text}\")\n",
    "                print(f\"\\tTranslated paragraph: {translated_text}\\n\")\n",
    "                \n",
    "                prompt = f\"\"\"Match each original text segment with its corresponding part from the translation.\n",
    "                Original segments: {[text for text in original_text_elements]}\n",
    "                Full original text: {original_text}\n",
    "                Full translation: {translated_text}\n",
    "                \n",
    "                Return a JSON object where keys are the original segments and values are their corresponding translations.\n",
    "                Only include segments that appear in the original text.\"\"\"\n",
    "                \n",
    "                try:\n",
    "                    response = self.client.chat.completions.create(\n",
    "                        model=self.pydentic_model,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You are a professional text alignment expert.\"},\n",
    "                            {\"role\": \"user\", \"content\": prompt}\n",
    "                        ],\n",
    "                        temperature=0.3,\n",
    "                        response_format={\"type\": \"json_object\"}\n",
    "                    )\n",
    "                    \n",
    "                    segment_mappings = json.loads(response.choices[0].message.content)\n",
    "                    \n",
    "                    for orig_text, trans_text in segment_mappings.items():\n",
    "                        if orig_text in translation_map:\n",
    "                            translation_map[orig_text] = trans_text\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"\\tError matching segments: {e}\")\n",
    "        \n",
    "        print(f\"\\tTranslation map: {translation_map}\")\n",
    "        return translation_map\n",
    "\n",
    "    def detect_pptx_language(self, text: str) -> str:\n",
    "        \"\"\"Detect language and return PowerPoint language code.\"\"\"\n",
    "        try:\n",
    "            # Detect language\n",
    "            detected_lang = detect(text)\n",
    "            # Convert to PowerPoint language code\n",
    "            pptx_lang = self.language_codes.get(detected_lang, \"en-US\")  # default to en-US if not found\n",
    "            return pptx_lang\n",
    "        except Exception as e:\n",
    "            print(f\"\\tLanguage detection error: {e}\")\n",
    "            return \"en-US\"  # default to en-US on error    \n",
    "\n",
    "    def process_slides(self, folder_path: str):\n",
    "        \"\"\"Main function to process all slides in the presentation.\"\"\"\n",
    "        slide_files = self.find_slide_files(folder_path)\n",
    "        \n",
    "        for slide_file in slide_files:\n",
    "            print(f\"\\nProcessing {os.path.basename(slide_file)}...\")\n",
    "            print(f\"Processing slide {slide_files.index(slide_file) + 1} of {len(slide_files)}...\")\n",
    "            \n",
    "            # Parse XML while preserving structure\n",
    "            tree = ET.parse(slide_file)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Extract namespaces from the root element\n",
    "            namespaces = {}\n",
    "            for key, value in root.attrib.items():\n",
    "                if key.startswith('xmlns:'):\n",
    "                    prefix = key.split(':')[1]\n",
    "                    namespaces[prefix] = value\n",
    "            \n",
    "            # Extract and create translation mapping\n",
    "            text_elements, original_text_elements = self.extract_text_runs(slide_file)\n",
    "            translation_map = self.create_translation_map(text_elements, original_text_elements)\n",
    "            \n",
    "            # Update text while preserving XML structure and whitespace\n",
    "            for original_text, translation in translation_map.items():\n",
    "                if not translation.strip():  # Skip empty translations\n",
    "                    continue\n",
    "                #Update Text\n",
    "                for element in root.findall('.//a:t', self.namespaces):\n",
    "                    if element.text and element.text.strip() == original_text:\n",
    "                        if translation.strip():  # If we have a valid translation\n",
    "                            # Preserve any leading/trailing whitespace from the original\n",
    "                            leading_space = ''\n",
    "                            trailing_space = ''\n",
    "                            if element.text.startswith(' '):\n",
    "                                leading_space = ' '\n",
    "                            if element.text.endswith(' '):\n",
    "                                trailing_space = ' '\n",
    "                            # Update text\n",
    "                            element.text = leading_space + translation.strip() + trailing_space\n",
    "\n",
    "                        else:\n",
    "                            # Find the parent run ('a:r') element and remove it\n",
    "                            parent_run = element.getparent()\n",
    "                            if parent_run is not None:\n",
    "                                parent_paragraph = parent_run.getparent()\n",
    "                                if parent_paragraph is not None:\n",
    "                                    parent_paragraph.remove(parent_run)\n",
    "\n",
    "                # Detect and update language\n",
    "                for run in root.findall('.//a:r', self.namespaces):\n",
    "                    text_elem = run.find('a:t', self.namespaces)\n",
    "                    if text_elem is not None:\n",
    "                        detected_lang = self.detect_pptx_language(text_elem.text.strip())\n",
    "                        # Find and update the language attribute in the corresponding rPr element\n",
    "                        parent_run = text_elem.getparent()\n",
    "                        if parent_run is not None:\n",
    "                            rPr = parent_run.find('a:rPr', self.namespaces)\n",
    "                        if rPr is not None:\n",
    "                                rPr.set('lang', detected_lang)\n",
    "                                print(f\"\\tUpdated language for '{translation.strip()}' to {detected_lang}\")\n",
    "                        # else:\n",
    "                        #     # Create rPr element if it doesn't exist\n",
    "                        #     rPr = ET.SubElement(run, f\"{{{self.namespaces['a']}}}rPr\")\n",
    "                        #     rPr.set('lang', detected_lang)\n",
    "                        #     print(f\"created property language for '{translation.strip()}' to {detected_lang}\")                                    \n",
    "\n",
    "            # Register extracted namespaces\n",
    "            for prefix, uri in namespaces.items():\n",
    "                ET.register_namespace(prefix, uri)\n",
    "            \n",
    "            # Register our known namespaces\n",
    "            for prefix, uri in self.namespaces.items():\n",
    "                ET.register_namespace(prefix, uri)\n",
    "            \n",
    "            # Write back XML while preserving declaration and namespaces\n",
    "            with open(slide_file, 'wb') as f:\n",
    "                tree.write(f, encoding='UTF-8', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline - Ppt to xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMLcreator(PowerpointPipeline):\n",
    "    def __init__(self, verbose: bool=False):\n",
    "        super().__init__(verbose=verbose)\n",
    "        # Initialize transformer and translator\n",
    "        self.transformer = PPTXTransformer(self.extract_path)\n",
    "\n",
    "    def extract_pptx(self):\n",
    "        \"\"\"Main method to handle the full translation process\"\"\"\n",
    "        try:\n",
    "            # Extract PPTX\n",
    "            self.transformer.extract_pptx(self.pptx_path)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error translating presentation: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipieline - Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerPointTranslator(PowerpointPipeline):\n",
    "    def __init__(self, target_language:str, Further_StyleInstructions:str=\"None\", Further_SpellCheckInstructions:str=\"None\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize transformer and translator\n",
    "        self.transformer = PPTXTransformer(self.extract_path)\n",
    "        self.spellchecker = SlideSpellChecker(Further_SpellCheckInstructions)\n",
    "        self.translator = SlideTranslator(target_language, Further_StyleInstructions)\n",
    "\n",
    "    def translate_presentation(self):\n",
    "        \"\"\"Main method to handle the full translation process\"\"\"\n",
    "        try:\n",
    "            # Extract PPTX\n",
    "            self.transformer.extract_pptx(self.pptx_path)\n",
    "            \n",
    "            #Get namespaces\n",
    "            namespaces = self.transformer.get_namespace()\n",
    "            self.translator.namespaces = namespaces\n",
    "            \n",
    "            # Process slides\n",
    "            self.translator.process_slides(self.extract_path)\n",
    "            \n",
    "            # Compose final PPTX\n",
    "            output_path = os.path.join(self.output_folder, self.output_pptx_name)\n",
    "            self.transformer.compose_pptx(self.extract_path, output_path)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error translating presentation: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... writing config\n",
      "... Creating PowerpointPipeline instance \n",
      "... Creating XMLcreator instance\n",
      "\tPPTX path: /Users/jwh/Code/SlideMob/Testpptx/presentation1.pptx\n",
      "\tExtract path: /Users/jwh/Code/SlideMob/extracted_pptx\n",
      "\tOutput folder: /Users/jwh/Code/SlideMob/output\n",
      "\tOutput PPTX name: translated_presentation1.pptx\n",
      "... Running extract_pptx on:\n",
      "... Creating PowerPointTranslator instance\n",
      "\tExtracted namespaces: {'a': 'http://schemas.openxmlformats.org/drawingml/2006/main', 'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships', 'p': 'http://schemas.openxmlformats.org/presentationml/2006/main'}\n",
      "\n",
      "Processing slide1.xml...\n",
      "Processing slide 1 of 3...\n",
      "Text elements found:\n",
      "- This is the presentation title | lang: en-GB\n",
      "- Second textblock | lang: en-GB\n",
      "\tLLM fed text: This is the presentation title\n",
      "\tOriginal paragraph: This is the presentation title\n",
      "\tTranslated paragraph: Dies ist der Präsentationstitel\n",
      "\n",
      "\tLLM fed text: Second textblock\n",
      "\tOriginal paragraph: Second textblock\n",
      "\tTranslated paragraph: Zweiter Textblock\n",
      "\n",
      "\tTranslation map: {'Second': 'Zweiter', 'textblock': 'Textblock', 'This is the presentation title': 'Dies ist der Präsentationstitel'}\n",
      "Error translating presentation: 'xml.etree.ElementTree.Element' object has no attribute 'getparent'\n",
      "Translation failed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root_folder = \"/Users/jwh/Code/SlideMob\"\n",
    "    pptx_folder = \"Testpptx\"\n",
    "    pptx_name = \"presentation1.pptx\"\n",
    "    extract_folder = \"extracted_pptx\"\n",
    "    outputfolder = \"output\"\n",
    "\n",
    "    print(\"... writing config\")\n",
    "    with open(\"config.json\", \"w\") as f:\n",
    "        json.dump({\"root_folder\": root_folder, \"pptx_folder\": pptx_folder, \"pptx_name\": pptx_name, \"extract_folder\": extract_folder, \"output_folder\": outputfolder}, f)\n",
    "\n",
    "    print(\"... Creating PowerpointPipeline instance \")\n",
    "    PowerpointPipeline_instance = PowerpointPipeline()\n",
    "\n",
    "    extract = True\n",
    "    spellcheck = False\n",
    "    improve = False\n",
    "    translate = True\n",
    "    align = False\n",
    "    consistency = False\n",
    "\n",
    "    if extract:\n",
    "        print(\"... Creating XMLcreator instance\")\n",
    "        XMLcreator_instance = XMLcreator(verbose=True)\n",
    "        print(\"... Running extract_pptx on:\")\n",
    "        success = XMLcreator_instance.extract_pptx()\n",
    "\n",
    "    if translate:\n",
    "        print(\"... Creating PowerPointTranslator instance\")\n",
    "        translator = PowerPointTranslator(\n",
    "            target_language=\"German\",\n",
    "            Further_StyleInstructions=\"None\",\n",
    "        )\n",
    "        success = translator.translate_presentation()\n",
    "\n",
    "\n",
    "        print(f\"Translation completed successfully. File saved to: {translator.output_folder}/{translator.output_pptx_name}\") if success else print(\"Translation failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stdui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
