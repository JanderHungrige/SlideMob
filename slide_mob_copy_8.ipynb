{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "#pptx transformation imports\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "# translator import\n",
    "import xml.etree.ElementTree as ET\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom pptx to xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPTXTransformer:\n",
    "    def __init__(self, extract_path: str):\n",
    "        self.extract_path = extract_path\n",
    "        self.namespaces = None\n",
    "\n",
    "    def extract_pptx(self, pptx_path: str) -> str:\n",
    "        \"\"\"Extract a PPTX file into its XML components.\"\"\"\n",
    "        os.makedirs(self.extract_path, exist_ok=True)\n",
    "        \n",
    "        with zipfile.ZipFile(pptx_path, 'r') as pptx:\n",
    "            pptx.extractall(self.extract_path)\n",
    "        \n",
    "        # Get namespaces right after extraction\n",
    "        self.namespaces = self.get_namespace()\n",
    "        return self.extract_path\n",
    "\n",
    "    def get_namespace(self) -> dict:\n",
    "        \"\"\"Get the namespaces from the first slide XML using text processing.\"\"\"\n",
    "        slide_path = os.path.join(self.extract_path, 'ppt/slides/slide1.xml')\n",
    "        \n",
    "        try:\n",
    "            with open(slide_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                \n",
    "            # Find the root element opening tag\n",
    "            start_idx = content.find('<p:sld')\n",
    "            end_idx = content.find('>', start_idx)\n",
    "            if start_idx == -1 or end_idx == -1:\n",
    "                print(\"Could not find root element\")\n",
    "                return {}\n",
    "            \n",
    "            # Extract the root element declaration\n",
    "            root_declaration = content[start_idx:end_idx]\n",
    "            \n",
    "            # Find all xmlns declarations\n",
    "            namespaces = {}\n",
    "            import re\n",
    "            \n",
    "            # Pattern to match xmlns:prefix=\"uri\" or xmlns=\"uri\"\n",
    "            pattern = r'xmlns(?::([^=]+))?=\"([^\"]+)\"'\n",
    "            matches = re.finditer(pattern, root_declaration)\n",
    "            \n",
    "            for match in matches:\n",
    "                prefix = match.group(1)  # This might be None for default namespace\n",
    "                uri = match.group(2)\n",
    "                if prefix:\n",
    "                    namespaces[prefix] = uri\n",
    "                else:\n",
    "                    namespaces['default'] = uri\n",
    "            \n",
    "            print(\"Extracted namespaces:\", namespaces)\n",
    "            return namespaces\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting namespaces: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def compose_pptx(self, source_path: str, output_pptx: str):\n",
    "        \"\"\"Compose a PPTX file from a directory containing the XML structure.\"\"\"\n",
    "        os.makedirs(os.path.dirname(output_pptx), exist_ok=True)\n",
    "        \n",
    "        with zipfile.ZipFile(output_pptx, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "            for root, _, files in os.walk(source_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, source_path)\n",
    "                    zf.write(file_path, arcname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationResponse(BaseModel):\n",
    "    translation: str\n",
    "\n",
    "class SlideTranslator():\n",
    "    def __init__(self, target_language: str, api_key: str, model: str=\"gpt-4\", Further_StyleInstructions:str=\"None\"):\n",
    "        self.model = model\n",
    "        self.pydentic_model=\"gpt-4-turbo-preview\"\n",
    "        self.target_language = target_language\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.namespaces = {'a': 'http://schemas.openxmlformats.org/drawingml/2006/main'}\n",
    "\n",
    "        if Further_StyleInstructions != \"None\":\n",
    "            self.Further_StyleInstructions = f\" Here are some further wording style instructions: {self.Further_StyleInstructions}\"\n",
    "        else:\n",
    "            self.Further_StyleInstructions = \"\"\n",
    "            \n",
    "    def find_slide_files(self, root_folder: str) -> List[str]:\n",
    "        \"\"\"Find all slide XML files in the folder structure.\"\"\"\n",
    "        slide_files = []\n",
    "        for root, _, files in os.walk(root_folder):\n",
    "            for file in files:\n",
    "                if file.startswith('slide') and file.endswith('.xml'):\n",
    "                    number_part = file[5:-4]\n",
    "                    if number_part.isdigit():\n",
    "                        slide_files.append(os.path.join(root, file))\n",
    "        return sorted(slide_files)\n",
    "\n",
    "    def extract_text_runs(self, xml_file: str) -> Tuple[List[ET.Element], set]:\n",
    "        \"\"\"Extract text elements that need translation.\"\"\"\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        text_elements = []\n",
    "        original_text_elements = set()\n",
    "  \n",
    "        # Create a backup with the original text elements\n",
    "        for paragraph in root.findall('.//a:p', self.namespaces):\n",
    "            for run in paragraph.findall('.//a:r', self.namespaces):\n",
    "                for original_text_element in run.findall('.//a:t', self.namespaces):\n",
    "                    if original_text_element.text and original_text_element.text.strip():\n",
    "                        original_text_elements.add(original_text_element.text.strip())\n",
    "\n",
    "        # Process paragraphs while preserving structure\n",
    "        for paragraph in root.findall('.//a:p', self.namespaces):\n",
    "            text_parts = []\n",
    "            for text_element in paragraph.findall('.//a:t', self.namespaces):\n",
    "                if text_element.text and text_element.text.strip():\n",
    "                    text_parts.append(text_element.text.strip())\n",
    "            \n",
    "            if text_parts:\n",
    "                text_element = ET.Element('a:t')\n",
    "                text_element.text = ' '.join(text_parts)\n",
    "                text_elements.append(text_element)\n",
    "\n",
    "        print(\"Text elements found:\")\n",
    "        for element in text_elements:\n",
    "            print(f\"- {element.text.strip()}\")     \n",
    "        return text_elements, original_text_elements\n",
    "\n",
    "    def translate_text(self, text: str) -> str:\n",
    "        \"\"\"Translate text while preserving approximate length and formatting.\"\"\"\n",
    "        prompt = f\"\"\"Translate following this instructions: Maintain similar total character length and preserve any special formatting or technical terms. For the translation do not return any other text than the pure translation.\n",
    "        Translate the text to {self.target_language}.{self.Further_StyleInstructions} Text to translate: {text}\n",
    "        \"\"\"\n",
    "\n",
    "        pydentic_prompt_addition = f\"Respond with a JSON object containing only a 'translation' field with the {self.target_language} translation of this text\"\n",
    "        \n",
    "        if self.model == \"gpt-4\": #non pydentic model\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.3,\n",
    "                )\n",
    "                return response.choices[0].message.content.strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Translation error: {e}\")\n",
    "                return text\n",
    "        else: #pydentic model   \n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt + pydentic_prompt_addition}\n",
    "                    ],\n",
    "                    temperature=0.3,\n",
    "                    response_format={ \"type\": \"json_object\" }\n",
    "                )\n",
    "                translation_response = TranslationResponse.model_validate_json(\n",
    "                    response.choices[0].message.content\n",
    "                )\n",
    "                return translation_response.translation.strip()\n",
    "    \n",
    "            except Exception as e:\n",
    "                if \"Error code: 400\" in str(e):\n",
    "                    print(f\"ERROR We use Pydentic, therefore the model must support json output (e.g. gpt-4-turbo-preview)| Translation error: {e}\")\n",
    "                else:\n",
    "                    print(f\"Translation error: {e}\")    \n",
    "                return text\n",
    "\n",
    "    def create_translation_map(self, text_elements: List[ET.Element], original_text_elements: set) -> dict:\n",
    "        \"\"\"Create a mapping between original text and their translations.\"\"\"\n",
    "        translation_map = {text: \"\" for text in original_text_elements}\n",
    "        \n",
    "        for element in text_elements:\n",
    "            original_text = element.text.strip()\n",
    "            print(f\"LLM fed text: {original_text}\")\n",
    "            if original_text:\n",
    "                translated_text = self.translate_text(original_text)\n",
    "                print(f\"Original paragraph: {original_text}\")\n",
    "                print(f\"Translated paragraph: {translated_text}\\n\")\n",
    "                \n",
    "                prompt = f\"\"\"Match each original text segment with its corresponding part from the translation.\n",
    "                Original segments: {list(original_text_elements)}\n",
    "                Full original text: {original_text}\n",
    "                Full translation: {translated_text}\n",
    "                \n",
    "                Return a JSON object where keys are the original segments and values are their corresponding translations.\n",
    "                Only include segments that appear in the original text.\"\"\"\n",
    "                \n",
    "                try:\n",
    "                    response = self.client.chat.completions.create(\n",
    "                        model=self.pydentic_model,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You are a professional text alignment expert.\"},\n",
    "                            {\"role\": \"user\", \"content\": prompt}\n",
    "                        ],\n",
    "                        temperature=0.3,\n",
    "                        response_format={\"type\": \"json_object\"}\n",
    "                    )\n",
    "                    \n",
    "                    segment_mappings = json.loads(response.choices[0].message.content)\n",
    "                    \n",
    "                    for orig_text, trans_text in segment_mappings.items():\n",
    "                        if orig_text in translation_map:\n",
    "                            translation_map[orig_text] = trans_text\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error matching segments: {e}\")\n",
    "        \n",
    "        print(f\"Translation map: {translation_map}\")\n",
    "        return translation_map\n",
    "\n",
    "    def process_slides(self, folder_path: str):\n",
    "        \"\"\"Main function to process all slides in the presentation.\"\"\"\n",
    "        slide_files = self.find_slide_files(folder_path)\n",
    "        \n",
    "        for slide_file in slide_files:\n",
    "            print(f\"\\nProcessing {os.path.basename(slide_file)}...\")\n",
    "            \n",
    "            # Parse XML while preserving structure\n",
    "            tree = ET.parse(slide_file)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Extract namespaces from the root element\n",
    "            namespaces = {}\n",
    "            for key, value in root.attrib.items():\n",
    "                if key.startswith('xmlns:'):\n",
    "                    prefix = key.split(':')[1]\n",
    "                    namespaces[prefix] = value\n",
    "            \n",
    "            # Extract and create translation mapping\n",
    "            text_elements, original_text_elements = self.extract_text_runs(slide_file)\n",
    "            translation_map = self.create_translation_map(text_elements, original_text_elements)\n",
    "            \n",
    "            # Update text while preserving XML structure and whitespace\n",
    "            for original_text, translation in translation_map.items():\n",
    "                for element in root.findall('.//a:t', self.namespaces):\n",
    "                    if element.text and element.text.strip() == original_text:\n",
    "                        # Preserve any leading/trailing whitespace from the original\n",
    "                        leading_space = ''\n",
    "                        trailing_space = ''\n",
    "                        if element.text.startswith(' '):\n",
    "                            leading_space = ' '\n",
    "                        if element.text.endswith(' '):\n",
    "                            trailing_space = ' '\n",
    "                        element.text = leading_space + translation.strip() + trailing_space\n",
    "\n",
    "            # Register extracted namespaces\n",
    "            for prefix, uri in namespaces.items():\n",
    "                ET.register_namespace(prefix, uri)\n",
    "            \n",
    "            # Register our known namespaces\n",
    "            for prefix, uri in self.namespaces.items():\n",
    "                ET.register_namespace(prefix, uri)\n",
    "            \n",
    "            # Write back XML while preserving declaration and namespaces\n",
    "            with open(slide_file, 'wb') as f:\n",
    "                tree.write(f, encoding='UTF-8', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerPointTranslator:\n",
    "    def __init__(self, root_folder: str, pptx_name: str, target_language: str, model:str, api_key: str, Further_StyleInstructions:str=\"None\"):\n",
    "        self.root_folder = root_folder\n",
    "        self.pptx_path = os.path.join(root_folder, pptx_name)\n",
    "        self.extract_path = os.path.join(root_folder, 'extracted_pptx')\n",
    "        self.output_folder = os.path.join(root_folder, 'translated_pptx')\n",
    "        self.output_pptx_name = f'translated_{pptx_name}'\n",
    "        # self.default_namespace =  {\n",
    "        #     'a': 'http://schemas.openxmlformats.org/drawingml/2006/main',\n",
    "        #     'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships',\n",
    "        #     'p': 'http://schemas.openxmlformats.org/presentationml/2006/main',\n",
    "        #     'a16': 'http://schemas.microsoft.com/office/drawing/2014/main',\n",
    "        #     'p14': 'http://schemas.microsoft.com/office/powerpoint/2010/main',\n",
    "        #     'mc': 'http://schemas.openxmlformats.org/markup-compatibility/2006',\n",
    "        #     'v': 'urn:schemas-microsoft-com:vml'\n",
    "        # }\n",
    "        \n",
    "        # Initialize transformer and translator\n",
    "        self.transformer = PPTXTransformer(self.extract_path)\n",
    "        self.translator = SlideTranslator(target_language, api_key, model, Further_StyleInstructions)\n",
    "\n",
    "    def translate_presentation(self):\n",
    "        \"\"\"Main method to handle the full translation process\"\"\"\n",
    "        try:\n",
    "            # Extract PPTX\n",
    "            self.transformer.extract_pptx(self.pptx_path)\n",
    "            \n",
    "            #Get namespaces\n",
    "            namespaces = self.transformer.get_namespace()\n",
    "            self.translator.namespaces = namespaces\n",
    "            \n",
    "            # Process slides\n",
    "            self.translator.process_slides(self.extract_path)\n",
    "            \n",
    "            # Compose final PPTX\n",
    "            output_path = os.path.join(self.output_folder, self.output_pptx_name)\n",
    "            self.transformer.compose_pptx(self.extract_path, output_path)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error translating presentation: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted namespaces: {'a': 'http://schemas.openxmlformats.org/drawingml/2006/main', 'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships', 'p': 'http://schemas.openxmlformats.org/presentationml/2006/main'}\n",
      "Extracted namespaces: {'a': 'http://schemas.openxmlformats.org/drawingml/2006/main', 'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships', 'p': 'http://schemas.openxmlformats.org/presentationml/2006/main'}\n",
      "\n",
      "Processing slide1.xml...\n",
      "Text elements found:\n",
      "- Delivering tangible results for ASML with Data & AI\n",
      "- ASML x Eraneos Analytics\n",
      "- October 2024\n",
      "- Regulation and Governance AI at ASML\n",
      "LLM fed text: Delivering tangible results for ASML with Data & AI\n",
      "Original paragraph: Delivering tangible results for ASML with Data & AI\n",
      "Translated paragraph: Erzielung greifbarer Ergebnisse für ASML mit Daten & KI\n",
      "\n",
      "LLM fed text: ASML x Eraneos Analytics\n",
      "Original paragraph: ASML x Eraneos Analytics\n",
      "Translated paragraph: ASML x Eraneos Analytics\n",
      "\n",
      "LLM fed text: October 2024\n",
      "Original paragraph: October 2024\n",
      "Translated paragraph: Oktober 2024\n",
      "\n",
      "LLM fed text: Regulation and Governance AI at ASML\n",
      "Original paragraph: Regulation and Governance AI at ASML\n",
      "Translated paragraph: Regulierung und Governance KI bei ASML\n",
      "\n",
      "Translation map: {'October 2024': 'Oktober 2024', 'Delivering tangible results for ASML with Data & AI': 'Erzielung greifbarer Ergebnisse für ASML mit Daten & KI', 'ASML x Eraneos Analytics': 'ASML x Eraneos Analytics', 'Regulation and Governance AI at ASML': 'Regulierung und Governance KI bei ASML'}\n",
      "\n",
      "Processing slide10.xml...\n",
      "Text elements found:\n",
      "- Projects involving regulations and governance often require significant manual effort - leveraging AI can substantially reduce this workload\n",
      "- Navigating constantly changing regulations at national and local levels is challenging. Gathering accurate information for informed decisions takes time . Using wrong, or outdated information can lead to quality issues, delays, or legal risks.\n",
      "- We understand these challenges and have the expertise to streamline this process.\n",
      "- Information gathering\n",
      "- Information\n",
      "- processing\n",
      "- Quality check\n",
      "- Decision making\n",
      "- Situation\n",
      "- In our experience, regulatory documents can run into the thousands per project, making it a tedious, unrewarding part of the project process.\n",
      "- 10\n",
      "LLM fed text: Projects involving regulations and governance often require significant manual effort - leveraging AI can substantially reduce this workload\n",
      "Original paragraph: Projects involving regulations and governance often require significant manual effort - leveraging AI can substantially reduce this workload\n",
      "Translated paragraph: Projekte, die Vorschriften und Governance betreffen, erfordern oft erheblichen manuellen Aufwand - der Einsatz von KI kann diese Arbeitsbelastung erheblich reduzieren.\n",
      "\n",
      "LLM fed text: Navigating constantly changing regulations at national and local levels is challenging. Gathering accurate information for informed decisions takes time . Using wrong, or outdated information can lead to quality issues, delays, or legal risks.\n",
      "Original paragraph: Navigating constantly changing regulations at national and local levels is challenging. Gathering accurate information for informed decisions takes time . Using wrong, or outdated information can lead to quality issues, delays, or legal risks.\n",
      "Translated paragraph: Die ständige Navigation durch sich ständig ändernde Vorschriften auf nationaler und lokaler Ebene ist herausfordernd. Das Sammeln genauer Informationen für fundierte Entscheidungen braucht Zeit. Die Verwendung falscher oder veralteter Informationen kann zu Qualitätsproblemen, Verzögerungen oder rechtlichen Risiken führen.\n",
      "\n",
      "LLM fed text: We understand these challenges and have the expertise to streamline this process.\n",
      "Original paragraph: We understand these challenges and have the expertise to streamline this process.\n",
      "Translated paragraph: Wir verstehen diese Herausforderungen und haben das Know-how, diesen Prozess zu optimieren.\n",
      "\n",
      "LLM fed text: Information gathering\n",
      "Original paragraph: Information gathering\n",
      "Translated paragraph: Informationssammlung\n",
      "\n",
      "LLM fed text: Information\n",
      "Original paragraph: Information\n",
      "Translated paragraph: Information\n",
      "\n",
      "LLM fed text: processing\n",
      "Original paragraph: processing\n",
      "Translated paragraph: Verarbeitung\n",
      "\n",
      "LLM fed text: Quality check\n",
      "Original paragraph: Quality check\n",
      "Translated paragraph: Qualitätskontrolle\n",
      "\n",
      "LLM fed text: Decision making\n",
      "Original paragraph: Decision making\n",
      "Translated paragraph: Entscheidungsfindung\n",
      "\n",
      "LLM fed text: Situation\n",
      "Original paragraph: Situation\n",
      "Translated paragraph: Situation\n",
      "\n",
      "LLM fed text: In our experience, regulatory documents can run into the thousands per project, making it a tedious, unrewarding part of the project process.\n",
      "Original paragraph: In our experience, regulatory documents can run into the thousands per project, making it a tedious, unrewarding part of the project process.\n",
      "Translated paragraph: In unserer Erfahrung können regulatorische Dokumente pro Projekt in die Tausende gehen, was es zu einem mühsamen, undankbaren Teil des Projektprozesses macht.\n",
      "\n",
      "LLM fed text: 10\n",
      "Original paragraph: 10\n",
      "Translated paragraph: 10\n",
      "\n",
      "Translation map: {'Information': 'Information', 'processing': 'processing', 'AI can substantially reduce this workload': 'AI can substantially reduce this workload', 'In our experience, regulatory documents can run into the thousands per project, making it a tedious, unrewarding part of the project process.': 'In our experience, regulatory documents can run into the thousands per project, making it a tedious, unrewarding part of the project process.', 'Decision making': 'Decision making', 'Gathering accurate information for informed decisions takes time': 'Gathering accurate information for informed decisions takes time', 'Navigating constantly changing regulations at national and local levels is challenging.': 'Navigating constantly changing regulations at national and local levels is challenging.', 'leveraging': 'leveraging', '.': '.', 'Quality check': 'Quality check', 'We understand these challenges and have the expertise to streamline this process.': 'We understand these challenges and have the expertise to streamline this process.', 'Using wrong, or outdated information can lead to quality issues, delays, or legal risks.': 'Using wrong, or outdated information can lead to quality issues, delays, or legal risks.', 'Information gathering': 'Information gathering', 'Projects involving regulations and governance often require significant manual effort -': 'Projects involving regulations and governance often require significant manual effort -', 'Situation': 'Situation'}\n",
      "\n",
      "Processing slide11.xml...\n",
      "Text elements found:\n",
      "- Regulatory, …\n",
      "- documents\n",
      "- Project data\n",
      "- Critical documents\n",
      "- Standard\n",
      "- documents\n",
      "- GenAI\n",
      "- Project documents\n",
      "- Expert\n",
      "- check\n",
      "- Document\n",
      "- adaption\n",
      "- Quick check\n",
      "- 10%\n",
      "- 90%\n",
      "- Expert AI-assistance\n",
      "- Reducing the manual workload by using AI to pinpoint the critical documents\n",
      "- AI can support with information gathering and processing as well as with risk and impact assessment.\n",
      "- Experts only need to manually review a small fraction of cases (here e.g., 10%), allowing them to focus on the most critical ones.\n",
      "- Regulations, requirements, laws, etc. must be checked by experts to make informed decisions.\n",
      "- This will not be eliminated by AI. However, we can reduce the amount of information to be screened .\n",
      "- Highlighting, preprocessing, and presenting important information and their interdependencies boosts the information gathering and decision-making process.\n",
      "- This reduces time and costs; and it allows experts to focus on more complex and strategic activities that require critical thinking and creativity.\n",
      "LLM fed text: Regulatory, …\n",
      "Original paragraph: Regulatory, …\n",
      "Translated paragraph: Regulatorisch, ...\n",
      "\n",
      "LLM fed text: documents\n",
      "Original paragraph: documents\n",
      "Translated paragraph: Dokumente\n",
      "\n",
      "LLM fed text: Project data\n",
      "Original paragraph: Project data\n",
      "Translated paragraph: Projektdaten\n",
      "\n",
      "LLM fed text: Critical documents\n",
      "Original paragraph: Critical documents\n",
      "Translated paragraph: Kritische Dokumente\n",
      "\n",
      "LLM fed text: Standard\n",
      "Original paragraph: Standard\n",
      "Translated paragraph: Standard\n",
      "\n",
      "LLM fed text: documents\n",
      "Original paragraph: documents\n",
      "Translated paragraph: Dokumente\n",
      "\n",
      "LLM fed text: GenAI\n",
      "Original paragraph: GenAI\n",
      "Translated paragraph: GenAI\n",
      "\n",
      "LLM fed text: Project documents\n",
      "Original paragraph: Project documents\n",
      "Translated paragraph: Projektunterlagen\n",
      "\n",
      "LLM fed text: Expert\n",
      "Original paragraph: Expert\n",
      "Translated paragraph: Experte\n",
      "\n",
      "LLM fed text: check\n",
      "Original paragraph: check\n",
      "Translated paragraph: überprüfen\n",
      "\n",
      "LLM fed text: Document\n",
      "Original paragraph: Document\n",
      "Translated paragraph: Dokument\n",
      "\n",
      "LLM fed text: adaption\n",
      "Original paragraph: adaption\n",
      "Translated paragraph: Anpassung\n",
      "\n",
      "LLM fed text: Quick check\n",
      "Original paragraph: Quick check\n",
      "Translated paragraph: Schnellprüfung\n",
      "\n",
      "LLM fed text: 10%\n",
      "Original paragraph: 10%\n",
      "Translated paragraph: 10%\n",
      "\n",
      "LLM fed text: 90%\n",
      "Original paragraph: 90%\n",
      "Translated paragraph: 90%\n",
      "\n",
      "LLM fed text: Expert AI-assistance\n",
      "Original paragraph: Expert AI-assistance\n",
      "Translated paragraph: Experten KI-Assistenz\n",
      "\n",
      "LLM fed text: Reducing the manual workload by using AI to pinpoint the critical documents\n",
      "Original paragraph: Reducing the manual workload by using AI to pinpoint the critical documents\n",
      "Translated paragraph: Verringerung der manuellen Arbeitsbelastung durch den Einsatz von KI zur Identifizierung kritischer Dokumente\n",
      "\n",
      "LLM fed text: AI can support with information gathering and processing as well as with risk and impact assessment.\n",
      "Original paragraph: AI can support with information gathering and processing as well as with risk and impact assessment.\n",
      "Translated paragraph: KI kann bei der Informationsbeschaffung und -verarbeitung sowie bei der Risiko- und Auswirkungsbeurteilung unterstützen.\n",
      "\n",
      "LLM fed text: Experts only need to manually review a small fraction of cases (here e.g., 10%), allowing them to focus on the most critical ones.\n",
      "Original paragraph: Experts only need to manually review a small fraction of cases (here e.g., 10%), allowing them to focus on the most critical ones.\n",
      "Translated paragraph: Experten müssen nur einen kleinen Bruchteil der Fälle manuell überprüfen (hier z.B. 10%), was es ihnen ermöglicht, sich auf die kritischsten zu konzentrieren.\n",
      "\n",
      "LLM fed text: Regulations, requirements, laws, etc. must be checked by experts to make informed decisions.\n",
      "Original paragraph: Regulations, requirements, laws, etc. must be checked by experts to make informed decisions.\n",
      "Translated paragraph: Vorschriften, Anforderungen, Gesetze usw. müssen von Experten überprüft werden, um fundierte Entscheidungen zu treffen.\n",
      "\n",
      "LLM fed text: This will not be eliminated by AI. However, we can reduce the amount of information to be screened .\n",
      "Original paragraph: This will not be eliminated by AI. However, we can reduce the amount of information to be screened .\n",
      "Translated paragraph: Dies wird nicht durch KI eliminiert. Wir können jedoch die Menge der zu überprüfenden Informationen reduzieren.\n",
      "\n",
      "LLM fed text: Highlighting, preprocessing, and presenting important information and their interdependencies boosts the information gathering and decision-making process.\n",
      "Original paragraph: Highlighting, preprocessing, and presenting important information and their interdependencies boosts the information gathering and decision-making process.\n",
      "Translated paragraph: Hervorhebung, Vorverarbeitung und Präsentation wichtiger Informationen und ihrer Zusammenhänge fördert den Informationsbeschaffungs- und Entscheidungsprozess.\n",
      "\n",
      "LLM fed text: This reduces time and costs; and it allows experts to focus on more complex and strategic activities that require critical thinking and creativity.\n",
      "Original paragraph: This reduces time and costs; and it allows experts to focus on more complex and strategic activities that require critical thinking and creativity.\n",
      "Translated paragraph: Dies reduziert Zeit und Kosten; und es ermöglicht Experten, sich auf komplexere und strategische Aktivitäten zu konzentrieren, die kritisches Denken und Kreativität erfordern.\n",
      "\n",
      "Translation map: {'check': 'prüfung', '90%': '90%', 'AI can support with information gathering and processing as well as with risk and impact assessment.': 'KI kann bei der Informationsbeschaffung und -verarbeitung sowie bei der Risiko- und Auswirkungsbeurteilung unterstützen.', 'must be checked by experts': 'müssen von Experten überprüft werden', 'Highlighting, preprocessing, and presenting important information and their interdependencies': 'Hervorhebung, Vorverarbeitung und Präsentation wichtiger Informationen und ihrer Zusammenhänge', 'Critical documents': 'Kritische Dokumente', 'boosts the information gathering': 'fördert den Informationsbeschaffungs-', 'This will not be eliminated by AI. However, we can': 'Dies wird nicht durch KI eliminiert. Wir können jedoch', 'Reducing the manual workload by using AI to': 'Verringerung der manuellen Arbeitsbelastung durch den Einsatz von KI zur', 'Expert': 'Experte', 'Regulations, requirements, laws,': 'Vorschriften, Anforderungen, Gesetze', 'GenAI': 'GenAI', '10%': '10%', 'Project': 'Projekt', 'Experts only need to manually review a small fraction of cases': 'Experten müssen nur einen kleinen Bruchteil der Fälle manuell überprüfen', 'documents': 'unterlagen', 'Regulatory, …': 'Regulatorisch, ...', 'pinpoint the critical documents': 'Identifizierung kritischer Dokumente', 'adaption': 'Anpassung', 'Project data': 'Projektdaten', 'Document': 'Dokument', 'and decision-making process.': 'und Entscheidungsprozess.', 'Standard': 'Standard', 'Quick': 'Schnell', 'experts to focus': 'Experten, sich zu konzentrieren', 'reduce the amount of information to be screened': 'die Menge der zu überprüfenden Informationen reduzieren', '(here e.g., 10%), allowing them to focus on the most critical ones.': '(hier z.B. 10%), was es ihnen ermöglicht, sich auf die kritischsten zu konzentrieren.', 'Expert AI-assistance': 'Experten KI-Assistenz', '.': '', 'etc.': 'usw.', 'to make informed decisions.': 'um fundierte Entscheidungen zu treffen.', 'on more complex and strategic activities that require critical thinking and creativity.': 'auf komplexere und strategische Aktivitäten, die kritisches Denken und Kreativität erfordern.', 'This reduces time and costs; and it allows': 'Dies reduziert Zeit und Kosten; und es ermöglicht'}\n",
      "\n",
      "Processing slide12.xml...\n",
      "Text elements found:\n",
      "- Start small – think big - scale fast\n",
      "- Let’s start with understanding your specific challenges and opportunities.\n",
      "- We build tailored solutions that meet your specific needs.\n",
      "- 1\n",
      "- Together with your subject matter experts, we will look at your processes and tasks to design a tailor-made solution\n",
      "- We suggest a first meeting to understand your specific needs in detail\n",
      "- Our dedicated AI design sprint workshop might be a good option to identify challenges and low hanging fruits which allows specifying key use-cases with a clear benefit\n",
      "- If there is a clear benefit and we agree to tackle the identified opportunities together, we will create a scalable, custom-build solution in close collaboration with your subject matter experts and stakeholders\n",
      "- 2\n",
      "- 3\n",
      "- 4\n",
      "- 12\n",
      "LLM fed text: Start small – think big - scale fast\n",
      "Original paragraph: Start small – think big - scale fast\n",
      "Translated paragraph: Fang klein an - denk groß - skaliere schnell\n",
      "\n",
      "LLM fed text: Let’s start with understanding your specific challenges and opportunities.\n",
      "Original paragraph: Let’s start with understanding your specific challenges and opportunities.\n",
      "Translated paragraph: Beginnen wir damit, Ihre spezifischen Herausforderungen und Chancen zu verstehen.\n",
      "\n",
      "LLM fed text: We build tailored solutions that meet your specific needs.\n",
      "Original paragraph: We build tailored solutions that meet your specific needs.\n",
      "Translated paragraph: Wir erstellen maßgeschneiderte Lösungen, die Ihren spezifischen Bedürfnissen entsprechen.\n",
      "\n",
      "LLM fed text: 1\n",
      "Original paragraph: 1\n",
      "Translated paragraph: 1\n",
      "\n",
      "LLM fed text: Together with your subject matter experts, we will look at your processes and tasks to design a tailor-made solution\n",
      "Original paragraph: Together with your subject matter experts, we will look at your processes and tasks to design a tailor-made solution\n",
      "Translated paragraph: Gemeinsam mit Ihren Fachexperten werden wir uns Ihre Prozesse und Aufgaben ansehen, um eine maßgeschneiderte Lösung zu entwerfen.\n",
      "\n",
      "LLM fed text: We suggest a first meeting to understand your specific needs in detail\n",
      "Original paragraph: We suggest a first meeting to understand your specific needs in detail\n",
      "Translated paragraph: Wir schlagen ein erstes Treffen vor, um Ihre spezifischen Bedürfnisse im Detail zu verstehen.\n",
      "\n",
      "LLM fed text: Our dedicated AI design sprint workshop might be a good option to identify challenges and low hanging fruits which allows specifying key use-cases with a clear benefit\n",
      "Original paragraph: Our dedicated AI design sprint workshop might be a good option to identify challenges and low hanging fruits which allows specifying key use-cases with a clear benefit\n",
      "Translated paragraph: Unser spezieller AI-Design-Sprint-Workshop könnte eine gute Option sein, um Herausforderungen und leicht zu erreichende Ziele zu identifizieren, die es ermöglichen, Schlüsselanwendungsfälle mit einem klaren Nutzen zu spezifizieren.\n",
      "\n",
      "LLM fed text: If there is a clear benefit and we agree to tackle the identified opportunities together, we will create a scalable, custom-build solution in close collaboration with your subject matter experts and stakeholders\n",
      "Original paragraph: If there is a clear benefit and we agree to tackle the identified opportunities together, we will create a scalable, custom-build solution in close collaboration with your subject matter experts and stakeholders\n",
      "Translated paragraph: Wenn es einen klaren Nutzen gibt und wir uns darauf einigen, die identifizierten Chancen gemeinsam anzugehen, werden wir in enger Zusammenarbeit mit Ihren Fachexperten und Stakeholdern eine skalierbare, individuell erstellte Lösung schaffen.\n",
      "\n",
      "LLM fed text: 2\n",
      "Original paragraph: 2\n",
      "Translated paragraph: 2\n",
      "\n",
      "LLM fed text: 3\n",
      "Original paragraph: 3\n",
      "Translated paragraph: 3\n",
      "\n",
      "LLM fed text: 4\n",
      "Original paragraph: 4\n",
      "Translated paragraph: 4\n",
      "\n",
      "LLM fed text: 12\n",
      "Original paragraph: 12\n",
      "Translated paragraph: 12\n",
      "\n",
      "Translation map: {'Let’s start with understanding your specific challenges and opportunities.': '1', '4': '4', 'We build tailored solutions': '2', 'Together with your subject matter experts, we will look at your processes and tasks to design a tailor-made solution': '3', 'We suggest a first meeting to understand your specific needs in detail': '5', '1': '1', 'If there is a clear benefit and we agree to tackle the identified opportunities together, we will create a scalable, custom-build solution in close collaboration with your subject matter experts and stakeholders': '6', '2': '2', '3': '3', 'Our dedicated AI design sprint workshop might be a good option to identify challenges and low hanging fruits which allows specifying key use-cases with a clear benefit': '7', 'that meet your specific needs.': '8', 'Start small – think big - scale fast': '9'}\n",
      "\n",
      "Processing slide13.xml...\n",
      "Text elements found:\n",
      "- Case Study Legal AI We successfully solved a Legal AI challenge in the automotive industry\n",
      "- 13\n",
      "LLM fed text: Case Study Legal AI We successfully solved a Legal AI challenge in the automotive industry\n",
      "Original paragraph: Case Study Legal AI We successfully solved a Legal AI challenge in the automotive industry\n",
      "Translated paragraph: Fallstudie Rechtliche KI Wir haben erfolgreich eine rechtliche KI-Herausforderung in der Automobilindustrie gelöst\n",
      "\n",
      "LLM fed text: 13\n",
      "Original paragraph: 13\n",
      "Translated paragraph: 13\n",
      "\n",
      "Translation map: {'Case Study Legal AI': 'Estudio de Caso de IA Legal', 'We successfully solved a Legal AI challenge in the automotive industry': 'Resolvimos con éxito un desafío de IA Legal en la industria automotriz'}\n",
      "\n",
      "Processing slide14.xml...\n",
      "Text elements found:\n",
      "- 14\n",
      "- A utomotive Industry C ase |  Summary\n",
      "- LegalAI , an LLM-powered support of the legal compliance assessment of digital vehicle services\n",
      "- Situation\n",
      "- The development, introduction and operation of digital vehicle services worldwide requires consideration of the regulatory framework and its legal risks. Each country is subject to different jurisdictions, while services are developed centrally.\n",
      "- Challenge\n",
      "- Traditionally, the legal evaluation of a digital service can take up to three months, while the PI-based development usually takes less time to release a feature. This makes it impossible to achieve the targeted volume of assessed cases per year in terms of time, quantity and cost.\n",
      "- Solution\n",
      "- A generative-AI-enabled solution supports the legal risk assessment of digital vehicle services on a digital platform. The rolled-out solution is expected to reduce the time-to-market timeline for all legal assessments by up to 60% and the costs by 50% to 99%, for high-risk and low-risk cases, respectively.\n",
      "- WirtschaftsWoche Best of Consulting 2024 Gewinner des Branchenpreises Automotive\n",
      "- WirtschaftsWoche\n",
      "- Awarded for In-house Legal Team Innovation in New Products and Services together with CARIAD and Freshfields Bruckhaus Deringer\n",
      "- Financial Times 2024\n",
      "- Europe Innovative Lawyers Award 2024\n",
      "LLM fed text: 14\n",
      "Original paragraph: 14\n",
      "Translated paragraph: 14\n",
      "\n",
      "LLM fed text: A utomotive Industry C ase |  Summary\n",
      "Original paragraph: A utomotive Industry C ase |  Summary\n",
      "Translated paragraph: Automobilindustrie Fall | Zusammenfassung\n",
      "\n",
      "LLM fed text: LegalAI , an LLM-powered support of the legal compliance assessment of digital vehicle services\n",
      "Original paragraph: LegalAI , an LLM-powered support of the legal compliance assessment of digital vehicle services\n",
      "Translated paragraph: LegalAI, eine LLM-gesteuerte Unterstützung der rechtlichen Konformitätsbewertung digitaler Fahrzeugdienste\n",
      "\n",
      "LLM fed text: Situation\n",
      "Original paragraph: Situation\n",
      "Translated paragraph: Situation\n",
      "\n",
      "LLM fed text: The development, introduction and operation of digital vehicle services worldwide requires consideration of the regulatory framework and its legal risks. Each country is subject to different jurisdictions, while services are developed centrally.\n",
      "Original paragraph: The development, introduction and operation of digital vehicle services worldwide requires consideration of the regulatory framework and its legal risks. Each country is subject to different jurisdictions, while services are developed centrally.\n",
      "Translated paragraph: Die Entwicklung, Einführung und Betrieb von digitalen Fahrzeugdiensten weltweit erfordert die Berücksichtigung des regulatorischen Rahmens und seiner rechtlichen Risiken. Jedes Land unterliegt verschiedenen Gerichtsbarkeiten, während Dienstleistungen zentral entwickelt werden.\n",
      "\n",
      "LLM fed text: Challenge\n",
      "Original paragraph: Challenge\n",
      "Translated paragraph: Herausforderung\n",
      "\n",
      "LLM fed text: Traditionally, the legal evaluation of a digital service can take up to three months, while the PI-based development usually takes less time to release a feature. This makes it impossible to achieve the targeted volume of assessed cases per year in terms of time, quantity and cost.\n",
      "Original paragraph: Traditionally, the legal evaluation of a digital service can take up to three months, while the PI-based development usually takes less time to release a feature. This makes it impossible to achieve the targeted volume of assessed cases per year in terms of time, quantity and cost.\n",
      "Translated paragraph: Traditionell kann die rechtliche Bewertung eines digitalen Dienstes bis zu drei Monate dauern, während die PI-basierte Entwicklung in der Regel weniger Zeit benötigt, um ein Feature freizugeben. Dies macht es unmöglich, das angestrebte Volumen an bewerteten Fällen pro Jahr in Bezug auf Zeit, Menge und Kosten zu erreichen.\n",
      "\n",
      "LLM fed text: Solution\n",
      "Original paragraph: Solution\n",
      "Translated paragraph: Lösung\n",
      "\n",
      "LLM fed text: A generative-AI-enabled solution supports the legal risk assessment of digital vehicle services on a digital platform. The rolled-out solution is expected to reduce the time-to-market timeline for all legal assessments by up to 60% and the costs by 50% to 99%, for high-risk and low-risk cases, respectively.\n",
      "Original paragraph: A generative-AI-enabled solution supports the legal risk assessment of digital vehicle services on a digital platform. The rolled-out solution is expected to reduce the time-to-market timeline for all legal assessments by up to 60% and the costs by 50% to 99%, for high-risk and low-risk cases, respectively.\n",
      "Translated paragraph: Eine generative-KI-gestützte Lösung unterstützt die rechtliche Risikobewertung von digitalen Fahrzeugdiensten auf einer digitalen Plattform. Es wird erwartet, dass die eingeführte Lösung die Markteinführungszeit für alle rechtlichen Bewertungen um bis zu 60% und die Kosten um 50% bis 99% für Hochrisiko- und Niedrigrisikofälle reduziert.\n",
      "\n",
      "LLM fed text: WirtschaftsWoche Best of Consulting 2024 Gewinner des Branchenpreises Automotive\n",
      "Original paragraph: WirtschaftsWoche Best of Consulting 2024 Gewinner des Branchenpreises Automotive\n",
      "Translated paragraph: WirtschaftsWoche Best of Consulting 2024 Gewinner des Branchenpreises Automobilindustrie\n",
      "\n",
      "LLM fed text: WirtschaftsWoche\n",
      "Original paragraph: WirtschaftsWoche\n",
      "Translated paragraph: WirtschaftsWoche\n",
      "\n",
      "LLM fed text: Awarded for In-house Legal Team Innovation in New Products and Services together with CARIAD and Freshfields Bruckhaus Deringer\n",
      "Original paragraph: Awarded for In-house Legal Team Innovation in New Products and Services together with CARIAD and Freshfields Bruckhaus Deringer\n",
      "Translated paragraph: Ausgezeichnet für Innovationen des internen Rechtsteams in neuen Produkten und Dienstleistungen zusammen mit CARIAD und Freshfields Bruckhaus Deringer\n",
      "\n",
      "LLM fed text: Financial Times 2024\n",
      "Original paragraph: Financial Times 2024\n",
      "Translated paragraph: Finanzzeiten 2024\n",
      "\n",
      "LLM fed text: Europe Innovative Lawyers Award 2024\n",
      "Original paragraph: Europe Innovative Lawyers Award 2024\n",
      "Translated paragraph: Europa Innovationsanwälte Preis 2024\n",
      "\n",
      "Translation map: {'2024': '2024', 'Automotive': 'Automobilindustrie', 'WirtschaftsWoche': 'WirtschaftsWoche', '|  Summary': '| Zusammenfassung', 'des': 'des', 'C': 'C', 'LegalAI': 'LegalAI', 'Europe Innovative Lawyers Award 2024': 'Europa Innovationsanwälte Preis 2024', 'The': 'The', 'Industry': 'Industrie', 'The development, introduction and operation of digital vehicle services worldwide requires consideration of the regulatory framework and its legal risks. Each country is subject to different jurisdictions, while services are developed centrally.': 'The development, introduction and operation of digital vehicle services worldwide requires consideration of the regulatory framework and its legal risks. Each country is subject to different jurisdictions, while services are developed centrally.', 'utomotive': 'utomotive', ',': ',', 'Solution': 'Lösung', 'Branchenpreises': 'Branchenpreises', 'Traditionally, the legal evaluation of a digital service can take up to three months, while the PI-based development usually takes less time to release a feature. This makes it impossible to achieve the targeted volume of assessed cases per year in terms of time, quantity and cost.': 'Traditionell kann die rechtliche Bewertung eines digitalen Dienstes bis zu drei Monate dauern, während die PI-basierte Entwicklung in der Regel weniger Zeit benötigt, um ein Feature freizugeben. Dies macht es unmöglich, das angestrebte Volumen an bewerteten Fällen pro Jahr in Bezug auf Zeit, Menge und Kosten zu erreichen.', 'A generative-AI-enabled solution supports the legal risk assessment of digital vehicle services on a digital platform.': 'Eine generative-KI-gestützte Lösung unterstützt die rechtliche Risikobewertung von digitalen Fahrzeugdiensten auf einer digitalen Plattform.', 'Challenge': 'Herausforderung', 'A': 'A', 'Awarded for In-house Legal Team Innovation in New Products and Services': 'Ausgezeichnet für Innovationen des internen Rechtsteams in neuen Produkten und Dienstleistungen', 'Best of Consulting 2024': 'Best of Consulting 2024', 'ase': 'ase', 'rolled-out solution is expected to reduce the time-to-market timeline for all legal assessments by up to 60% and the costs by 50% to 99%,': 'rolled-out solution is expected to reduce the time-to-market timeline for all legal assessments by up to 60% and the costs by 50% to 99%,', 'Gewinner': 'Gewinner', 'Situation': 'Situation', 'an LLM-powered support of the legal compliance assessment of digital vehicle services': 'an LLM-powered support of the legal compliance assessment of digital vehicle services', 'together with CARIAD and Freshfields Bruckhaus Deringer': 'zusammen mit CARIAD und Freshfields Bruckhaus Deringer', 'for high-risk and low-risk cases, respectively.': 'für Hochrisiko- und Niedrigrisikofälle reduziert.', 'Financial Times': 'Finanzzeiten'}\n",
      "\n",
      "Processing slide15.xml...\n",
      "Text elements found:\n",
      "- A utomotive Industry C ase | Our Solution Approach\n",
      "- LegalAI , an LLM-powered support of the legal compliance assessment of digital vehicle services\n",
      "- A generative-AI-enabled solution supports the legal risk assessment of all digital vehicle services on a digital platform.\n",
      "- Software development and risk assessment processes are streamlined. Developers receive a pre-assessment at a click of a button, legal experts can focus on high-risk cases and specific requests based on the pre-assessment.\n",
      "- AI assesses the risks of a digital service and its functions\n",
      "Risks are assessed on the basis of country-specific legal requirements\n",
      "A list of measures addresses open questions and (potential) risks and thus supports Product Owners in making their service legally compliant\n",
      "- Risk Score\n",
      "- Global Risk Assessment\n",
      "- Selection of Vehicle Services\n",
      "LLM fed text: A utomotive Industry C ase | Our Solution Approach\n",
      "Original paragraph: A utomotive Industry C ase | Our Solution Approach\n",
      "Translated paragraph: Automobilindustrie Fallstudie | Unser Lösungsansatz\n",
      "\n",
      "LLM fed text: LegalAI , an LLM-powered support of the legal compliance assessment of digital vehicle services\n",
      "Original paragraph: LegalAI , an LLM-powered support of the legal compliance assessment of digital vehicle services\n",
      "Translated paragraph: LegalAI, eine LLM-gestützte Unterstützung der rechtlichen Konformitätsbewertung digitaler Fahrzeugdienste\n",
      "\n",
      "LLM fed text: A generative-AI-enabled solution supports the legal risk assessment of all digital vehicle services on a digital platform.\n",
      "Original paragraph: A generative-AI-enabled solution supports the legal risk assessment of all digital vehicle services on a digital platform.\n",
      "Translated paragraph: Eine generative-KI-gestützte Lösung unterstützt die rechtliche Risikobewertung aller digitalen Fahrzeugdienste auf einer digitalen Plattform.\n",
      "\n",
      "LLM fed text: Software development and risk assessment processes are streamlined. Developers receive a pre-assessment at a click of a button, legal experts can focus on high-risk cases and specific requests based on the pre-assessment.\n",
      "Original paragraph: Software development and risk assessment processes are streamlined. Developers receive a pre-assessment at a click of a button, legal experts can focus on high-risk cases and specific requests based on the pre-assessment.\n",
      "Translated paragraph: Softwareentwicklung und Risikobewertungsprozesse sind optimiert. Entwickler erhalten eine Vorab-Bewertung per Knopfdruck, Rechtsexperten können sich auf Hochrisikofälle und spezifische Anfragen basierend auf der Vorab-Bewertung konzentrieren.\n",
      "\n",
      "LLM fed text: AI assesses the risks of a digital service and its functions\n",
      "Risks are assessed on the basis of country-specific legal requirements\n",
      "A list of measures addresses open questions and (potential) risks and thus supports Product Owners in making their service legally compliant\n",
      "Original paragraph: AI assesses the risks of a digital service and its functions\n",
      "Risks are assessed on the basis of country-specific legal requirements\n",
      "A list of measures addresses open questions and (potential) risks and thus supports Product Owners in making their service legally compliant\n",
      "Translated paragraph: KI bewertet die Risiken eines digitalen Dienstes und seiner Funktionen\n",
      "Risiken werden auf der Grundlage länderspezifischer gesetzlicher Anforderungen bewertet\n",
      "Eine Liste von Maßnahmen beantwortet offene Fragen und (potenzielle) Risiken und unterstützt somit Produktbesitzer dabei, ihren Dienst gesetzeskonform zu machen\n",
      "\n",
      "LLM fed text: Risk Score\n",
      "Original paragraph: Risk Score\n",
      "Translated paragraph: Risikobewertung\n",
      "\n",
      "LLM fed text: Global Risk Assessment\n",
      "Original paragraph: Global Risk Assessment\n",
      "Translated paragraph: Globale Risikobewertung\n",
      "\n",
      "LLM fed text: Selection of Vehicle Services\n",
      "Original paragraph: Selection of Vehicle Services\n",
      "Translated paragraph: Auswahl an Fahrzeugdienstleistungen\n",
      "\n",
      "Translation map: {'Industry': None, 'a': None, 'AI assesses the risks of a digital service and its functions\\nRisks are assessed on the basis of country-specific legal requirements\\nA list of measures addresses open questions and (potential) risks and thus supports Product Owners in making their service legally compliant': None, 'an LLM-powered support of the legal compliance assessment of digital vehicle services': 'eine LLM-gestützte Unterstützung der rechtlichen Konformitätsbewertung digitaler Fahrzeugdienste', 'Software development and risk assessment processes are streamlined. Developers receive a pre-assessment at': None, 'C': None, 'A generative-AI-enabled solution supports the legal risk assessment of all digital vehicle services on a digital platform.': 'Eine generative-KI-gestützte Lösung unterstützt die rechtliche Risikobewertung aller digitalen Fahrzeugdienste auf einer digitalen Plattform.', 'click of a button, legal experts can focus on high-risk cases and specific requests based on the pre-assessment.': 'Knopfdruck, Rechtsexperten können sich auf Hochrisikofälle und spezifische Anfragen basierend auf der Vorab-Bewertung konzentrieren.', 'Risk Score': 'Risikobewertung', 'A': 'Automobilindustrie', 'utomotive': 'Fallstudie', 'LegalAI': 'LegalAI', 'ase': None, '| Our Solution Approach': '| Unser Lösungsansatz', 'Selection of Vehicle Services': 'Auswahl an Fahrzeugdienstleistungen', ',': None, 'Global Risk Assessment': 'Globale Risikobewertung'}\n",
      "Error translating presentation: 'NoneType' object has no attribute 'strip'\n",
      "Translation failed\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    root_folder = \"/Users/jwh/Code/Translator\"\n",
    "    pptx_name = \"2024-10-23_ASML_Regulation_and_Governance_GenAI.pptx\"\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    \n",
    "    translator = PowerPointTranslator(\n",
    "        root_folder=root_folder,\n",
    "        pptx_name=pptx_name,\n",
    "        target_language=\"German\",\n",
    "        model=\"gpt-4\",\n",
    "        api_key=openai_api_key,\n",
    "    )\n",
    "    \n",
    "    success = translator.translate_presentation()\n",
    "    print(f\"Translation completed successfully. File saved to: {translator.output_folder}/{translator.output_pptx_name}\") if success else print(\"Translation failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stdui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
